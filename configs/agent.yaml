pipeline: [ingest, dedupe_quality, categorize, cluster, captioner, publisher]
embeddings: {backend: openclip, model: ViT-B-32, pretrained: laion2b_s34b_b79k, device: cpu}
dedupe: {method: clip, clip_threshold: 0.800, near_dup_threshold: 5}
categorize:
  #labels: ["candid","portrait","group photo","stage","audience","speaker","award","sports","food","night","landscape","architecture","indoors","outdoors"]
  labels: ["group photo","people","nature","Lord Ganesha","food","night","landscape","indoors","outdoors","person"]
  threshold: 0.40   # raise for stricter tags (e.g., 0.32–0.36)
  topk: 3
cluster:
  use_clip: true
  k: auto
  max_images_per_post: 6
  use_label_features: false         # ← enable fusion
  label_weight: 0.35               # ← scales label scores before concat
  label_norm: zscore               # ← zscore | none
  fuse_normalize: true             # ← L2-normalize fused vectors
  selection: {k: 48}
captioner:
  mode: "template"          # "template" (now) | "blip2" (optional future)
  montage_max_tiles: 9      # how many images to pack into the grid
  montage_tile_px: 384      # tile size (px) before packing
  adapter_path: "checkpoints/lora_blip2_montage/best"
  max_hashtags: 15
  include_swipe_hint: false
  calc_clipscore: true      # compute cosine(img, caption) scores
  openers:
    - "Highlights from"
    - "Moments from"
    - "Scenes from"
    - "Snapshots of"
  base_hashtags: ["#IITGuwahati", "#Montage", "#PhotographyClub"]
  label_hashtags:          # extend as you like
    "portrait": ["#Portrait", "#Faces"]
    "group photo": ["#GroupShot", "#Team"]
    "stage": ["#Stage", "#Concert", "#Live"]
    "audience": ["#Audience", "#Vibes"]
    "speaker": ["#Speaker", "#Talk"]
    "award": ["#Awards", "#Winners"]
    "sports": ["#Sports", "#Action"]
    "food": ["#Food", "#Treats"]
    "night": ["#Night", "#LowLight"]
    "indoors": ["#Indoors"]
    "outdoors": ["#Outdoors"]
publisher: {enabled: false, dry_run: true}

